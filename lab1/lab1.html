<!DOCTYPE html>
<!-- saved from url=(0040)https://nctu-sslab.github.io/PP-f20/HW1/ -->
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Parallel Programming @ NCTU, Fall 2020 | This is the webpage for the Parallel Programming course</title>
<meta name="generator" content="Jekyll v3.9.0">
<meta property="og:title" content="Parallel Programming @ NCTU, Fall 2020">
<meta property="og:locale" content="en_US">
<meta name="description" content="This is the webpage for the Parallel Programming course">
<meta property="og:description" content="This is the webpage for the Parallel Programming course">
<link rel="canonical" href="https://nctu-sslab.github.io/PP-f20/HW1/">
<meta property="og:url" content="https://nctu-sslab.github.io/PP-f20/HW1/">
<meta property="og:site_name" content="Parallel Programming @ NCTU, Fall 2020">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Parallel Programming @ NCTU, Fall 2020">
<script type="application/ld+json">
{"description":"This is the webpage for the Parallel Programming course","headline":"Parallel Programming @ NCTU, Fall 2020","url":"https://nctu-sslab.github.io/PP-f20/HW1/","@type":"WebPage","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="./lab1_files/style.css">
  <style shopback-extension-v6-5-2="" data-styled-version="4.2.0"></style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
  <body><div id="MathJax_Message" style="display: none;"></div>
    <section class="page-header">
      <h1 class="project-name">Parallel Programming @ NCTU, Fall 2020</h1>
      <h2 class="project-tagline">This is the webpage for the Parallel Programming course</h2>
      
        <a href="https://github.com/nctu-sslab/PP-f20" class="btn">View on GitHub</a>
      
      
    </section>

    <section class="main-content">
      <script type="text/javascript" src="./lab1_files/MathJax.js.‰∏ãËºâ" async=""> </script>
<script type="text/x-mathjax-config;executed=true"> MathJax.Hub.Config({'HTML-CSS': { preferredFont: 'TeX', availableFonts: ['STIX','TeX'], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) }, tex2jax: { inlineMath: [ ['$', '$'] ], processEscapes: true, ignoreClass: 'tex2jax_ignore|dno',skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']}, TeX: {  noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } }, Macros: { href: '{}' } }, messageStyle: 'none' }); MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(), i; for(i=0; i < all.length; i += 1) { all[i].SourceElement().parentNode.className += ' has-jax'; } }); </script>

<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-TP966Z8H9W"></script>
<script> window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-TP966Z8H9W',{'page_path': location.pathname + location.search + location.hash}); </script>

<h1 id="programming-assignment-i-simd-programming">Programming Assignment I: SIMD Programming</h1>

<p>The purpose of this assignment is to familiarize yourself with SIMD (single instruction, multiple data) programming. Most modern processors include some form of vector operations (i.e., SIMD instructions), and some applications may take advantage of SIMD instructions to improve performance through vectorization. Although modern compilers support automatic vectorization optimizations, the capabilities of compilers to fully auto-vectorize a given piece of code are often limited. Fortunately, almost all compilers (targeted to processors with SIMD extensions) provide SIMD intrinsics to allow programmers to vectorize their code explicitly.</p>

<p>Please download the code and unzip it:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>wget https://nctu-sslab.github.io/PP-f20/HW1/HW1.zip
<span class="nv">$ </span>unzip HW1.zip <span class="nt">-d</span> HW1
<span class="nv">$ </span><span class="nb">chmod</span> <span class="nt">-R</span> 700 HW1 <span class="c"># avoid cheating</span>
<span class="nv">$ </span><span class="nb">cd </span>HW1
</code></pre></div></div>

<h2 id="1-part-1-vectorizing-code-using-fake-simd-intrinsics">1. Part 1: Vectorizing Code Using Fake SIMD Intrinsics</h2>

<p>Take a look at the function <code class="language-plaintext highlighter-rouge">clampedExpSerial</code> in <code class="language-plaintext highlighter-rouge">part1/main.cpp</code> of the Assignment I code base. The <code class="language-plaintext highlighter-rouge">clampedExp()</code> function raises <code class="language-plaintext highlighter-rouge">values[i]</code> to the power given by <code class="language-plaintext highlighter-rouge">exponents[i]</code> for all elements of the input array and clamps the resulting values at 9.999999. Your job is to vectorize this piece of code so it can be run on a machine with SIMD vector instructions.</p>

<p>Please enter the <code class="language-plaintext highlighter-rouge">part1</code> folder:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd </span>part1
</code></pre></div></div>

<p><strong>Rather than</strong> craft an implementation using <em>SSE</em> or <em>AVX2</em> vector intrinsics that map to real SIMD vector instructions on modern CPUs, to make things a little easier, we‚Äôre asking you to <strong><em>implement your version using PP‚Äôs ‚Äúfake vector intrinsics‚Äù defined in <code class="language-plaintext highlighter-rouge">PPintrin.h</code>.</em></strong> The <code class="language-plaintext highlighter-rouge">PPintrin.h</code> library provides you with a set of vector instructions that operate on vector values and/or vector masks. (These functions don‚Äôt translate to real CPU vector instructions, instead we simulate these operations for you in our library, and provide feedback that makes for easier debugging.)</p>

<p>As an example of using the PP intrinsics, a vectorized version of the <code class="language-plaintext highlighter-rouge">abs()</code> function is given in <code class="language-plaintext highlighter-rouge">main.cpp</code>. This example contains some basic vector loads and stores and manipulates mask registers.  Note that the <code class="language-plaintext highlighter-rouge">abs()</code> example is only a simple example, and in fact the code does not correctly handle all inputs! (We will let you figure out why!) You may wish to read through all the comments and function definitions in <code class="language-plaintext highlighter-rouge">PPintrin.h</code> to know what operations are available to you.</p>

<p>Here are few hints to help you in your implementation:</p>

<ul>
  <li>Every vector instruction is subject to an optional mask parameter.  The mask parameter defines which lanes whose output is ‚Äúmasked‚Äù for this operation. A 0 in the mask indicates a lane is masked, and so its value will not be overwritten by the results of the vector operation. If no mask is specified in the operation, no lanes are masked. (Note this equivalent to providing a mask of all ones.)</li>
  <li><em>Hint:</em> Your solution will need to use multiple mask registers and various mask operations provided in the library.</li>
  <li><em>Hint:</em> Use <code class="language-plaintext highlighter-rouge">_pp_cntbits</code> function helpful in this problem.</li>
  <li>Consider what might happen if the total number of loop iterations is not a multiple of SIMD vector width. We suggest you test your code with <code class="language-plaintext highlighter-rouge">./myexp -s 3</code>.</li>
  <li><em>Hint:</em> You might find <code class="language-plaintext highlighter-rouge">_pp_init_ones</code> helpful (use it to initialize any mask!).</li>
  <li><em>Hint:</em> Use <code class="language-plaintext highlighter-rouge">./myexp -l</code> to print a log of executed vector instruction at the end.  Use function <code class="language-plaintext highlighter-rouge">addUserLog()</code> to add customized debug information in log. Feel free to add additional <code class="language-plaintext highlighter-rouge">PPLogger.printLog()</code> to help you debug.</li>
</ul>

<p>The output of the program will tell you if your implementation generates correct output. If there are incorrect results, the program will print the first one it finds and print out a table of function inputs and outputs. Your function‚Äôs output is after ‚Äúoutput = ‚Äú, which should match with the results after ‚Äúgold = ‚Äú. The program also prints out a list of statistics describing utilization of the PP fake vector units. You should consider the performance of your implementation to be the value ‚ÄúTotal Vector  Instructions‚Äù. (You can assume every PP fake vector instruction takes one cycle on the PP fake SIMD CPU.) ‚ÄúVector Utilization‚Äù shows the percentage of vector lanes that are enabled.</p>

<p>See the <a href="https://nctu-sslab.github.io/PP-f20/HW1/#requirements">requirements</a> to finish this part.</p>

<blockquote>
  <p>The following part is not required for this assignment, but you are encouraged to do it for practice.</p>

  <p>Once you have finished part 1, it is time for vectorizing the code using real SIMD intrinsics and see  if the program can really get the benefits from vectorization. Vectorize the same piece of code in part 1 so it can be run on a machine with SIMD vector instructions.</p>

  <p>Intrinsics are exposed by the compiler as (inline) functions that are not part of any library. Of course the SIMD intrinsics depend on the underlying architecture, and may differ from one compiler to other even for a same SIMD instruction set. Fortunately, compilers tend to standardize intrinsics prototype for a given SIMD instruction set, and we only have to handle the differences between the various SIMD instruction sets.</p>
</blockquote>

<h2 id="2-part-2-vectorizing-code-with-automatic-vectorization-optimizations">2. Part 2: Vectorizing Code with Automatic Vectorization Optimizations</h2>

<p>Take the exercises below and answer questions <a href="https://nctu-sslab.github.io/PP-f20/HW1/#Q2-1">Q2-1</a>, <a href="https://nctu-sslab.github.io/PP-f20/HW1/#Q2-2">Q2-2</a>, and <a href="https://nctu-sslab.github.io/PP-f20/HW1/#Q2-3">Q2-3</a>.</p>

<p>We are going to start from scratch and try to let the compiler do the brunt of the work. You will notice that this is not a ‚Äúflip a switch and everything is good‚Äù exercise, but it also requires effort from the developer to write the code in a way that the compiler knows it can do these optimizations. The goal of this assignment is to learn how to fully exploit the optimization capabilities of the compiler such that in the future when you write code, you write it in a way that gets you the best performance for the least amount of effort.</p>

<p>Please enter the <code class="language-plaintext highlighter-rouge">part2</code> folder:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd </span>part2
</code></pre></div></div>

<p>Auto-vectorization is enabled by default at optimization levels <code class="language-plaintext highlighter-rouge">-O2</code> and <code class="language-plaintext highlighter-rouge">-O3</code>. We first use <code class="language-plaintext highlighter-rouge">-fno-vectorize</code> to disable automatic vectorization, and start with the following simple loop (in <code class="language-plaintext highlighter-rouge">test1.cpp</code>):</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">test1</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">__builtin_assume</span><span class="p">(</span><span class="n">N</span> <span class="o">==</span> <span class="mi">1024</span><span class="p">);</span>
  
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">I</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">c</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We have added an outer loop over <code class="language-plaintext highlighter-rouge">I</code> whose purpose is to eliminate measurement error in <code class="language-plaintext highlighter-rouge">gettime()</code>. Notice that <code class="language-plaintext highlighter-rouge">__builtin_assume(N == 1024)</code> tells the compiler more about the inputs of the program‚Äîsay this program is used in a mobile phone and always has the same input size‚Äîso that it can perform more optimizations.</p>

<p>You can compile this C++ code fragment with the following command and see the generated assembly code in <code class="language-plaintext highlighter-rouge">assembly/test1.novec.s</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make clean<span class="p">;</span> make test1.o <span class="nv">ASSEMBLE</span><span class="o">=</span>1
</code></pre></div></div>

<p>You are recommended to try out Compiler Explorer, a nifty online tool that provides an ‚Äúinteractive compiler‚Äù. <a href="https://godbolt.org/z/5PE6x9"><u>This link</u></a> is pre-configured for 10.0.1 version of <em>clang</em> and compiler flags from the makefile. (To manually configure yourself: select language C++, compiler version x86-64 <em>clang</em> 10.0.1 and enter flags <code class="language-plaintext highlighter-rouge">-O3 -std=c++17 -Wall -fno-vectorize</code>. A screenshot is shown below.</p>

<p><img alt="fno-vectorize" src="./lab1_files/93843680-3ec7d400-fccd-11ea-9c62-007db8c2f569.png"></p>

<h3 id="21-turning-on-auto-vectorization">2.1 Turning on auto-vectorization</h3>

<p>Let‚Äôs turn the compiler optimizations on and see how much the compiler can speed up the execution
of the program.</p>

<p>We remove <code class="language-plaintext highlighter-rouge">-fno-vectorize</code> from the compiler option to turn on the compiler optimizations, and add <code class="language-plaintext highlighter-rouge">-Rpass=loop-vectorize -Rpass-missed=loop-vectorize -Rpass-analysis=loop-vectorize</code> to get more information from <em>clang</em> about why it does or does not optimize code. This was done in the makefile, and you can enable auto-vectorization by typing the following command, which generates <code class="language-plaintext highlighter-rouge">assembly/test1.vec.s</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make clean<span class="p">;</span> make test1.o <span class="nv">ASSEMBLE</span><span class="o">=</span>1 <span class="nv">VECTORIZE</span><span class="o">=</span>1
</code></pre></div></div>

<p>You should see the following output, informing you that the loop has been vectorized. Although <em>clang</em> does tell you this, you should always look at the assembly to see exactly how it has been vectorized, since it is not guaranteed to be using the vector registers optimally.</p>

<pre><code class="language-log">test1.cpp:14:5: remark: vectorized loop (vectorization width: 4, interleaved count: 2) [-Rpass=loop-vectorize]
    for (int j=0; j&lt;N; j++) {
    ^
</code></pre>

<p>You can observe the difference between <code class="language-plaintext highlighter-rouge">test1.vec.s</code> and <code class="language-plaintext highlighter-rouge">test1.novec.s</code> with the following command or by changing the compiler flag on Compiler Explorer.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>diff assembly/test1.vec.s assembly/test1.novec.s
</code></pre></div></div>

<h3 id="22-adding-the-__restrict-qualifier">2.2 Adding the <code class="language-plaintext highlighter-rouge">__restrict</code> qualifier</h3>

<p>Now, if you inspect the assembly code‚Äîactually, you don‚Äôt need to do that, which is out of the scope of this assignment‚Äîyou will see the code first checks if there is a partial overlap between arrays <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">c</code> or arrays <code class="language-plaintext highlighter-rouge">b</code> and <code class="language-plaintext highlighter-rouge">c</code>. If there is an overlap, then it does a simple non-vectorized code. If there is no overlap, it does a vectorized version. The above can, at best, be called partially vectorized.</p>

<p>The problem is that the compiler is constrained by what we tell it about the arrays. If we tell it more, then perhaps it can do more optimization. The most obvious thing is to inform the compiler that no overlap is possible. This is done in standard C by using the <code class="language-plaintext highlighter-rouge">restrict</code> qualifier for the pointers. By adding this type qualifier, you can hint to the compiler that for the lifetime of the pointer, only the pointer itself or a value directly derived from it (such as <code class="language-plaintext highlighter-rouge">pointer + 1</code>) will be used to access the object to which it points.</p>

<p>C++ does not have standard support for <code class="language-plaintext highlighter-rouge">restrict</code>, but many compilers have equivalents that usually work in both C++ and C, such as the <em>GCC</em>‚Äôs and <em>clang</em>‚Äôs <code class="language-plaintext highlighter-rouge">__restrict__</code> (or <code class="language-plaintext highlighter-rouge">__restrict</code>), and Visual C++‚Äôs <code class="language-plaintext highlighter-rouge">__declspec(restrict)</code>.</p>

<p>The code after adding the <code class="language-plaintext highlighter-rouge">__restrict</code> qualifier is shown as follows.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">test</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="kr">__restrict</span> <span class="n">a</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="kr">__restrict</span> <span class="n">b</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="kr">__restrict</span> <span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">__builtin_assume</span><span class="p">(</span><span class="n">N</span> <span class="o">==</span> <span class="mi">1024</span><span class="p">);</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">I</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">c</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Let‚Äôs modify <code class="language-plaintext highlighter-rouge">test1.cpp</code> accordingly and recompile it again with the following command, which generates <code class="language-plaintext highlighter-rouge">assembly/test1.vec.restr.s</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make clean<span class="p">;</span> make test1.o <span class="nv">ASSEMBLE</span><span class="o">=</span>1 <span class="nv">VECTORIZE</span><span class="o">=</span>1 <span class="nv">RESTRICT</span><span class="o">=</span>1
</code></pre></div></div>

<p>Now you should see the generated code is better‚Äîthe code for checking possible overlap is gone‚Äîbut it is assuming the data are <strong>NOT</strong> 16 bytes aligned (<code class="language-plaintext highlighter-rouge">movups</code> is unaligned move). It also means that the loop above can not assume that the arrays are aligned.</p>

<p>If <em>clang</em> were smart, it could test for the cases where the arrays are either all aligned, or all unaligned, and have a fast inner loop. However, it is unable to do that currently.üôÅ</p>

<h3 id="23-adding-the-__builtin_assume_aligned-intrinsic">2.3 Adding the <code class="language-plaintext highlighter-rouge">__builtin_assume_aligned</code> intrinsic</h3>

<p>In order to get the performance we are looking for, we need to tell <em>clang</em> that the arrays are aligned. There are a couple of ways to do that. The first is to construct a (non-portable) aligned type, and use that in the function interface. The second is to add an intrinsic or three within the function itself. The second option is easier to implement on older code bases, as other functions calling the one to be vectorized do not have to be modified. The intrinsic has for this is called <code class="language-plaintext highlighter-rouge">__builtin_assume_aligned</code>:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">test</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="kr">__restrict</span> <span class="n">a</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="kr">__restrict</span> <span class="n">b</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="kr">__restrict</span> <span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">__builtin_assume</span><span class="p">(</span><span class="n">N</span> <span class="o">==</span> <span class="mi">1024</span><span class="p">);</span>
  <span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">__builtin_assume_aligned</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>
  <span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">__builtin_assume_aligned</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>
  <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">__builtin_assume_aligned</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>
  
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">I</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">c</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Let‚Äôs modify <code class="language-plaintext highlighter-rouge">test1.cpp</code> accordingly and recompile it again with the following command, which generates <code class="language-plaintext highlighter-rouge">assembly/test1.vec.restr.align.s</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make clean<span class="p">;</span> make test1.o <span class="nv">ASSEMBLE</span><span class="o">=</span>1 <span class="nv">VECTORIZE</span><span class="o">=</span>1 <span class="nv">RESTRICT</span><span class="o">=</span>1 <span class="nv">ALIGN</span><span class="o">=</span>1
</code></pre></div></div>

<p>Let‚Äôs see the difference:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>diff assembly/test1.vec.restr.s assembly/test1.vec.restr.align.s
</code></pre></div></div>

<p>Now finally, we get the nice tight vectorized code (<code class="language-plaintext highlighter-rouge">movaps</code> is aligned move.) we were looking for, because <em>clang</em> has used packed <em>SSE</em> instructions to add 16 bytes at a time. It also manages <code class="language-plaintext highlighter-rouge">load</code> and <code class="language-plaintext highlighter-rouge">store</code> two at a time, which it did not do last time. The question is now that we understand what we need to tell the compiler, how much more complex can the loop be before auto-vectorization fails.</p>

<h3 id="24-turning-on-avx2-instructions">2.4 Turning on AVX2 instructions</h3>

<p>Next, we try to turn on AVX2 instructions using the following command, which generates <code class="language-plaintext highlighter-rouge">assembly/test1.vec.restr.align.avx2.s</code></p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make clean<span class="p">;</span> make test1.o <span class="nv">ASSEMBLE</span><span class="o">=</span>1 <span class="nv">VECTORIZE</span><span class="o">=</span>1 <span class="nv">RESTRICT</span><span class="o">=</span>1 <span class="nv">ALIGN</span><span class="o">=</span>1 <span class="nv">AVX2</span><span class="o">=</span>1
</code></pre></div></div>

<p>Let‚Äôs see the difference:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>diff assembly/test1.vec.restr.align.s assembly/test1.vec.restr.align.avx2.s
</code></pre></div></div>

<p>We can see instructions with prefix <code class="language-plaintext highlighter-rouge">v*</code>. That‚Äôs good. We confirm the compiler uses AVX2 instructions; however, this code is still not aligned when using <em>AVX2</em> registers.</p>

<blockquote>
  <p><strong><em><a name="Q2-1">Q2-1</a>:</em></strong> Fix the code to make sure it uses aligned moves for the best performance.</p>

  <p>Hint: we want to see <code class="language-plaintext highlighter-rouge">vmovaps</code> rather than <code class="language-plaintext highlighter-rouge">vmovups</code>.</p>
</blockquote>

<h3 id="25-performance-impacts-of-vectorization">2.5 Performance impacts of vectorization</h3>

<p>Let‚Äôs see what speedup we get from vectorization. Build and run the program with the following configurations, which run <code class="language-plaintext highlighter-rouge">test1()</code> many times, and record the elapsed execution time.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># case 1</span>
<span class="nv">$ </span>make clean <span class="o">&amp;&amp;</span> make <span class="o">&amp;&amp;</span> ./test_auto_vectorize <span class="nt">-t</span> 1
<span class="c"># case 2</span>
<span class="nv">$ </span>make clean <span class="o">&amp;&amp;</span> make <span class="nv">VECTORIZE</span><span class="o">=</span>1 <span class="o">&amp;&amp;</span> ./test_auto_vectorize <span class="nt">-t</span> 1
<span class="c"># case 3</span>
<span class="nv">$ </span>make clean <span class="o">&amp;&amp;</span> make <span class="nv">VECTORIZE</span><span class="o">=</span>1 <span class="nv">AVX2</span><span class="o">=</span>1 <span class="o">&amp;&amp;</span> ./test_auto_vectorize <span class="nt">-t</span> 1
</code></pre></div></div>

<p>Note that you may wish to use the workstations provided by this course, which support <em>AVX2</em>; otherwise, you may get a message like ‚ÄúIllegal instruction (core dumped)‚Äù. You can check whether or not a machine supports the <em>AVX2</em> instructions by looking for <code class="language-plaintext highlighter-rouge">avx2</code> in the flags section of the output of <code class="language-plaintext highlighter-rouge">cat /proc/cpuinfo</code>.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> /proc/cpuinfo | <span class="nb">grep </span>avx2
</code></pre></div></div>

<blockquote>
  <p><strong><em><a name="Q2-2">Q2-2</a>:</em></strong> What speedup does the vectorized code achieve over the unvectorized code? What additional speedup does using <code class="language-plaintext highlighter-rouge">-mavx2</code> give (<code class="language-plaintext highlighter-rouge">AVX2=1</code> in the <code class="language-plaintext highlighter-rouge">Makefile</code>)? You may wish to run this experiment several times and take median elapsed times; you can report answers to the nearest 100% (e.g., 2√ó, 3√ó, etc). What can you infer about the bit width of the default vector registers on the PP machines? What about the bit width of the <em>AVX2</em> vector registers.</p>

  <p>Hint: Aside from speedup and the vectorization report, the most relevant information is that the data type for each array is <code class="language-plaintext highlighter-rouge">float</code>.</p>
</blockquote>

<p>You may also run <code class="language-plaintext highlighter-rouge">test2()</code> and <code class="language-plaintext highlighter-rouge">test3()</code> with <code class="language-plaintext highlighter-rouge">./test_auto_vectorize -t 2</code> and <code class="language-plaintext highlighter-rouge">./test_auto_vectorize -t 2</code>, respectively, before and after fixing the vectorization issues in Section 2.6.</p>

<h3 id="26--more-examples">2.6  More examples</h3>

<h4 id="261-example-2">2.6.1 Example 2</h4>

<p>Take a look at the second example below in <code class="language-plaintext highlighter-rouge">test2.cpp</code>:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kt">void</span> <span class="nf">test2</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="kr">__restrict</span> <span class="n">a</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="kr">__restrict</span> <span class="n">b</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="kr">__restrict</span> <span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span>
<span class="p">{</span>
  <span class="n">__builtin_assume</span><span class="p">(</span><span class="n">N</span> <span class="o">==</span> <span class="mi">1024</span><span class="p">);</span>
  <span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">__builtin_assume_aligned</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>
  <span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">__builtin_assume_aligned</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>
  <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span><span class="n">__builtin_assume_aligned</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">I</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
    <span class="p">{</span>
      <span class="cm">/* max() */</span>
      <span class="n">c</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
        <span class="n">c</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

</code></pre></div></div>

<p>Compile the code with the following command:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>make clean<span class="p">;</span> make test2.o <span class="nv">ASSEMBLE</span><span class="o">=</span>1 <span class="nv">VECTORIZE</span><span class="o">=</span>1
</code></pre></div></div>

<p>Note that the assembly was not vectorized. Now, change the function with a patch file (<code class="language-plaintext highlighter-rouge">test2.cpp.patch</code>), which is shown below, by running <code class="language-plaintext highlighter-rouge">patch -i ./test2.cpp.patch</code>.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gd">--- test2.cpp
</span><span class="gi">+++ test2.cpp
</span><span class="p">@@ -14,9 +14,8 @@</span>
     for (int j = 0; j &lt; N; j++)
     {
       /* max() */
<span class="gd">-      c[j] = a[j];
-      if (b[j] &gt; a[j])
-        c[j] = b[j];
</span><span class="gi">+      if (b[j] &gt; a[j]) c[j] = b[j];
+      else c[j] = a[j];
</span>     }
   }

</code></pre></div></div>

<p>Now, you actually see the vectorized assembly with the <code class="language-plaintext highlighter-rouge">movaps</code> and <code class="language-plaintext highlighter-rouge">maxps</code> instructions.</p>

<blockquote>
  <p><strong><em><a name="Q2-3">Q2-3</a>:</em></strong> Provide a theory for why the compiler is generating dramatically different assembly.</p>
</blockquote>

<h4 id="262-example-3">2.6.2 Example 3</h4>

<p>Take a look at the third example below in <code class="language-plaintext highlighter-rouge">test3.cpp</code>:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">double</span> <span class="nf">test3</span><span class="p">(</span><span class="kt">double</span><span class="o">*</span> <span class="kr">__restrict</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">__builtin_assume</span><span class="p">(</span><span class="n">N</span> <span class="o">==</span> <span class="mi">1024</span><span class="p">);</span>
  <span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="kt">double</span> <span class="o">*</span><span class="p">)</span><span class="n">__builtin_assume_aligned</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>

  <span class="kt">double</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">I</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">b</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">return</span> <span class="n">b</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Compile the code with the following command:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make clean<span class="p">;</span> make test3.o <span class="nv">ASSEMBLE</span><span class="o">=</span>1 <span class="nv">VECTORIZE</span><span class="o">=</span>1
</code></pre></div></div>

<p>You should see the non-vectorized code with the <code class="language-plaintext highlighter-rouge">addsd</code> instructions.</p>

<p>Notice that this does not actually vectorize as the <em>xmm</em> registers are operating on 8 byte chunks. The problem here is that <em>clang</em> is not allowed to re-order the operations we give it. Even though the the addition operation is associative with real numbers, they are not with floating point numbers. (Consider what happens with signed zeros, for example.)</p>

<p>Furthermore, we need to tell <em>clang</em> that reordering operations is okay with us. To do this, we need to add another compile-time flag, <code class="language-plaintext highlighter-rouge">-ffast-math</code>. Compile the program again with the following command:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>make clean<span class="p">;</span> make test3.o <span class="nv">ASSEMBLE</span><span class="o">=</span>1 <span class="nv">VECTORIZE</span><span class="o">=</span>1 <span class="nv">FASTMATH</span><span class="o">=</span>1
</code></pre></div></div>

<p>You should see the vectorized code with the <code class="language-plaintext highlighter-rouge">addpd</code> instructions.</p>

<h2 id="3-requirements">3. <a name="requirements">Requirements</a></h2>

<p>You will need to meet the following requirements and answer the questions (marked with ‚Äú<strong>Q1</strong> &amp; <strong>Q2</strong>‚Äù) in a <strong>REPORT</strong> using <a href="https://hackmd.io/">HackMD</a>. (Markdown is a common format that is widely used for developer documentation (e.g., GitHub), and HackMD is a markdown service which is free, powerful, and the most importantly made in Taiwan. To learn Markdown, you may refer to the video listed in the <a href="https://nctu-sslab.github.io/PP-f20/HW1/#References">references</a>.)</p>

<h3 id="31-part-1">3.1 Part 1</h3>

<ol>
  <li>Implement a vectorized version of <code class="language-plaintext highlighter-rouge">clampedExpSerial</code> in <code class="language-plaintext highlighter-rouge">clampedExpVector</code> (using fake vector intrinsics). Your implementation should work with any combination of input array size (<code class="language-plaintext highlighter-rouge">N</code>) and vector width (<code class="language-plaintext highlighter-rouge">VECTOR_WIDTH</code>), achieve a <strong>vector utilization higher than 60%</strong>, and of course <strong>pass the verification</strong>. (You can assume the array size is much bigger than the vector width.)</li>
  <li>
    <p>Run <code class="language-plaintext highlighter-rouge">./myexp -s 10000</code> and sweep the vector width from 2, 4, 8, to 16. Record the resulting vector utilization. You can do this by changing the <code class="language-plaintext highlighter-rouge">#define VECTOR_WIDTH</code> value in <code class="language-plaintext highlighter-rouge">def.h</code>. <strong>Q1-1</strong>: Does the vector utilization increase, decrease or stay the same as <code class="language-plaintext highlighter-rouge">VECTOR_WIDTH</code> changes? Why?</p>
  </li>
  <li><strong>Bonus</strong>: Implement a vectorized version of <code class="language-plaintext highlighter-rouge">arraySumSerial</code> in <code class="language-plaintext highlighter-rouge">arraySumVector</code>. Your implementation may assume that <code class="language-plaintext highlighter-rouge">VECTOR_WIDTH</code> is an even number and also a factor of the input array size <code class="language-plaintext highlighter-rouge">N</code>. Whereas the serial implementation has <code class="language-plaintext highlighter-rouge">O(N)</code> work-span, your implementation should have at most <code class="language-plaintext highlighter-rouge">O(N / VECTOR_WIDTH + log2(VECTOR_WIDTH))</code> span. You should achieve a vector utilization higher than 80% and pass the verification. You may find the <code class="language-plaintext highlighter-rouge">hadd</code> and <code class="language-plaintext highlighter-rouge">interleave</code> operations useful. (You can assume the array size is much bigger than the vector width.)</li>
</ol>

<h3 id="32-part-2">3.2 Part 2</h3>

<p>Answer the three questions (<a href="https://nctu-sslab.github.io/PP-f20/HW1/#Q2-1">Q2-1</a>, <a href="https://nctu-sslab.github.io/PP-f20/HW1/#Q2-2">Q2-2</a>, and <a href="https://nctu-sslab.github.io/PP-f20/HW1/#Q2-3">Q2-3</a>) embedded in part 2. We don‚Äôt test your code. If you have code for answering the questions, show the code and explain it thoroughly in your report.</p>

<h2 id="4-grading-policy">4. Grading Policy</h2>

<p><strong>NO CHEATING!!</strong> You will receive no credit if you are found cheating.</p>

<p>Total of 110%:</p>
<ul>
  <li>Part 1 (80%):
    <ul>
      <li>Correctness (60%):  A correct implementation of <code class="language-plaintext highlighter-rouge">clampedExpVector</code>. The <a href="https://nctu-sslab.github.io/PP-f20/HW1/#requirements">requirements</a> should be met. Notice that you will receive <strong>no credit</strong> if any of the requirements fails.</li>
      <li>Question (10%): <code class="language-plaintext highlighter-rouge">Q1-1</code> contributes 10%. Answer to the question will be classified into one of the four reward tiers: excellent (10%), good (7%), normal (3%), and terrible (0%).</li>
      <li>Bonus (10%): A correct implementation of <code class="language-plaintext highlighter-rouge">arraySumVector</code>. The <a href="https://nctu-sslab.github.io/PP-f20/HW1/#requirements">requirements</a> should be met. Notice that you will receive <strong>no credit</strong> if any of the requirements fails.</li>
    </ul>
  </li>
  <li>Part 2 (30%)
    <ul>
      <li>Questions: For <code class="language-plaintext highlighter-rouge">Q2-1</code>~<code class="language-plaintext highlighter-rouge">Q2-3</code>, each question contributes 10%. Answers to each question will be classified into one of the four reward tiers: excellent (10%), good (7%), normal (3%), and terrible (0%).</li>
    </ul>
  </li>
</ul>

<h2 id="5-evaluation-platform">5. Evaluation Platform</h2>

<p>Your program should be able to run on UNIX-like OS platforms. We will evaluate your programs on the workstations dedicated for this course. You can access these workstations by <code class="language-plaintext highlighter-rouge">ssh</code> with the following information. (To learn how to use <code class="language-plaintext highlighter-rouge">ssh</code> and <code class="language-plaintext highlighter-rouge">scp</code>, you can refer to the video listed in the <a href="https://nctu-sslab.github.io/PP-f20/HW1/#References">references</a>)</p>

<p>The workstations are based on Ubuntu 18.04 with Intel(R) Core(TM) i5-7500 CPU @ 3.40GHz processors. <code class="language-plaintext highlighter-rouge">g++-10</code>(used in part1) and <code class="language-plaintext highlighter-rouge">clang++-11</code>(used in part2) have been installed.</p>

<table>
  <thead>
    <tr>
      <th>IP</th>
      <th>Port</th>
      <th>User Name</th>
      <th>Password</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>140.113.215.195</td>
      <td>37076 ~ 37080</td>
      <td>{student_id}</td>
      <td>{Provided by TA}</td>
    </tr>
  </tbody>
</table>

<p>Login example:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>ssh &lt;student_id&gt;@140.113.215.195 <span class="nt">-p</span> &lt;port&gt;
</code></pre></div></div>

<h2 id="6-submission">6. Submission</h2>

<p>All your files should be organized in the following hierarchy and zipped into a <code class="language-plaintext highlighter-rouge">.zip</code> file, named <code class="language-plaintext highlighter-rouge">HW1_xxxxxxx.zip</code>, where <code class="language-plaintext highlighter-rouge">xxxxxxx</code> is your student ID.</p>

<p>Directory structure inside the zipped file:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">HW1_xxxxxxx.zip</code> (root)
    <ul>
      <li><code class="language-plaintext highlighter-rouge">vectorOP.cpp</code></li>
      <li><code class="language-plaintext highlighter-rouge">url.txt</code></li>
    </ul>
  </li>
</ul>

<p>Notice that you just need to provide the URL of your HackMD report in <code class="language-plaintext highlighter-rouge">url.txt</code>, and enable the write permission for someone who knows the URL so that TAs can give you feedback directly in your report.</p>

<p>You can use the testing script <code class="language-plaintext highlighter-rouge">test_hw1</code> to check your answer <em>for reference only</em>. Run <code class="language-plaintext highlighter-rouge">test_hw1</code> in a dictionary that contains your <code class="language-plaintext highlighter-rouge">HW1_XXXXXXX.zip</code> file on the workstation. <code class="language-plaintext highlighter-rouge">test_hw1</code> checks if the zip file is correct, and runs graders.</p>

<p>Be sure to upload your zipped file to new E3 e-Campus system by the due date.</p>

<p><strong>You will get <em>NO POINT</em> if your ZIP‚Äôs name is wrong or the ZIP hierarchy is incorrect.</strong></p>

<p><strong>Due Date: 23:59, October 22, Thursday, 2020</strong></p>

<h2 id="7-references">7. <a name="References">References</a></h2>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Analysis_of_parallel_algorithms">Wikipedia: Analysis of parallel algorithms</a></li>
  <li><a href="https://en.wikipedia.org/wiki/SIMD">Wikipedia: SIMD</a></li>
  <li><a href="https://clang.llvm.org/docs/LanguageExtensions.html#builtin-functions">Clang: built-in functions document</a></li>
  <li><a href="https://www.youtube.com/watch?v=Or6adjo3W4E&amp;list=PLCOCSTovXmudP_dZi1T9lNHLOtqpK9e2P&amp;index=19">Video: Markdown ‰ΩøÁî®ÊïôÂ≠∏</a></li>
  <li><a href="https://www.youtube.com/watch?v=PYdM2vN4BpE&amp;list=PLCOCSTovXmudP_dZi1T9lNHLOtqpK9e2P&amp;index=15">Video: SSH &amp; SCP ‰ΩøÁî®ÊïôÂ≠∏</a></li>
</ul>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/nctu-sslab/PP-f20">PP-f20</a> is maintained by <a href="https://github.com/nctu-sslab">nctu-sslab</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  

<div id="f9233eae-e624-4083-b047-5f4613e49a94-bottom"></div></body><div id="shopback-app" style="z-index: 2147483647 !important; display: block !important;"></div></html>